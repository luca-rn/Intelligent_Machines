{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtQNCj6vD9J5"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "7zzossW0EGjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "Vr6Gpt9qEK9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/data-yolo.zip'"
      ],
      "metadata": {
        "id": "wpaN_26NENoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# extract zip file\n",
        "download_folder = \"/content\"\n",
        "zip_name = \"data-yolo.zip\"\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(download_folder)\n",
        "\n",
        "print(f\"Extraction complete! Files saved to {download_folder}\")"
      ],
      "metadata": {
        "id": "MGiEld_rEQPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data into training and validation, still in yolo format\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "dataset_path = download_folder\n",
        "image_dir = os.path.join(dataset_path, \"images\")\n",
        "label_dir = os.path.join(dataset_path, \"labels\")\n",
        "\n",
        "# Output paths\n",
        "train_img = os.path.join(dataset_path, \"images/train\")\n",
        "val_img = os.path.join(dataset_path, \"images/val\")\n",
        "train_lbl = os.path.join(dataset_path, \"yolo/labels/train\")\n",
        "val_lbl = os.path.join(dataset_path, \"yolo/labels/val\")\n",
        "\n",
        "# Create train/val folders\n",
        "for d in [train_img, val_img, train_lbl, val_lbl]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# List images and shuffle\n",
        "images = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])  # Adjust for other image formats\n",
        "random.shuffle(images)\n",
        "\n",
        "# Split 80% train, 20% val\n",
        "split_idx = int(0.8 * len(images))\n",
        "train_files, val_files = images[:split_idx], images[split_idx:]\n",
        "\n",
        "# Move files\n",
        "for file_list, img_dest, lbl_dest in [(train_files, train_img, train_lbl), (val_files, val_img, val_lbl)]:\n",
        "    for file in file_list:\n",
        "        shutil.move(os.path.join(image_dir, file), os.path.join(img_dest, file))\n",
        "        label_file = file.replace(\".jpg\", \".txt\")  # Assuming YOLO format\n",
        "        if os.path.exists(os.path.join(label_dir, label_file)):\n",
        "            shutil.move(os.path.join(label_dir, label_file), os.path.join(lbl_dest, label_file))\n",
        "\n",
        "print(\"Dataset successfully split into training and validation sets!\")\n",
        "\n",
        "yolo_train_labels = train_lbl\n",
        "yolo_val_labels = val_lbl"
      ],
      "metadata": {
        "id": "kmz1Kbv0ESFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting from YOLO annotations to annotations for Faster RCNN\n",
        "\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "classes = [\"Exploding Kittens\", \"Munchkin\", \"Poker\", \"Uno\"]\n",
        "\n",
        "rcnn_train_labels = os.path.join(dataset_path, \"labels/train\")\n",
        "rcnn_val_labels = os.path.join(dataset_path, \"labels/val\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(rcnn_train_labels, exist_ok=True)\n",
        "os.makedirs(rcnn_val_labels, exist_ok=True)\n",
        "\n",
        "def yolo_to_rcnn_bbox(x_center, y_center, width, height, img_w, img_h):\n",
        "    x_center *= img_w\n",
        "    y_center *= img_h\n",
        "    width *= img_w\n",
        "    height *= img_h\n",
        "\n",
        "    x_min = x_center - width / 2\n",
        "    y_min = y_center - height / 2\n",
        "    x_max = x_center + width / 2\n",
        "    y_max = y_center + height / 2\n",
        "\n",
        "    return [x_min, y_min, x_max, y_max]\n",
        "\n",
        "\n",
        "def convert_yolo_folder_to_rcnn(yolo_folder,img_folder,out_folder):\n",
        "  for label_file in os.listdir(yolo_folder):\n",
        "    if not label_file.endswith('.txt'):\n",
        "        continue\n",
        "\n",
        "    img_name = label_file.replace('.txt', '.jpg')\n",
        "    img_path = os.path.join(img_folder, img_name)\n",
        "    label_path = os.path.join(yolo_folder, label_file)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\"Image not found for {label_file}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "    img_w, img_h = img.size\n",
        "\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    rcnn_lines = []\n",
        "    for line in lines:\n",
        "      class_id, x_c, y_c, w, h = map(float, line.strip().split())\n",
        "      x_min, y_min, x_max, y_max = yolo_to_rcnn_bbox(x_c, y_c, w, h, img_w, img_h)\n",
        "      rcnn_lines.append(f\"{int(class_id)} {x_min} {y_min} {x_max} {y_max}\")\n",
        "\n",
        "    output_file = os.path.join(out_folder, label_file)\n",
        "    with open(output_file, 'w') as f:\n",
        "      f.write(\"\\n\".join(rcnn_lines))\n",
        "\n",
        "    print(f'Converted labels from {yolo_folder} to {out_folder}')\n",
        "  return out_folder\n",
        "\n",
        "train_lbl = convert_yolo_folder_to_rcnn(yolo_train_labels, train_img, rcnn_train_labels)\n",
        "val_lbl = convert_yolo_folder_to_rcnn(yolo_val_labels, val_img, rcnn_val_labels)"
      ],
      "metadata": {
        "id": "xEdCiCIKEXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform(train):\n",
        "    transforms = []\n",
        "    # Converts PIL image to Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    # You can add data augmentation here for training\n",
        "    if train:\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "metadata": {
        "id": "bh5HQgFkFZ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_MAP = {0: \"Exploding Kittens\", 1: \"Munchkin\", 2: \"Poker\", 3: \"Uno\"}\n",
        "\n",
        "class CustomDetectionDataset(Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, transforms=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transforms = transforms\n",
        "        # List of image filenames\n",
        "        self.imgs = sorted([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_filename = self.imgs[idx]\n",
        "        img_path = os.path.join(self.images_dir, img_filename)\n",
        "        label_path = os.path.join(self.labels_dir, os.path.splitext(img_filename)[0] + '.txt')\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Parse annotation file\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                cls = int(parts[0])\n",
        "                x_min, y_min, x_max, y_max = map(float, parts[1:])\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "                labels.append(cls)\n",
        "\n",
        "        # Convert to tensors\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': image_id,\n",
        "            'area': area,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n"
      ],
      "metadata": {
        "id": "GDaJLSEwEeAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collate function needed for batching variable-size targets\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "# Load datasets\n",
        "data_dir = './'\n",
        "train_dataset = CustomDetectionDataset(\n",
        "    images_dir=train_img, train_lbl, transforms=get_transform(train=True)\n",
        ")\n",
        "val_dataset = CustomDetectionDataset(\n",
        "    images_dir=val_img, val_lbl, transforms=get_transform(train=False)\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=4, shuffle=True, num_workers=4,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=2, shuffle=False, num_workers=2,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "iOGgocm5Fhf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Build model\n",
        "num_classes = len(CLASS_MAP) + 1  # +1 for background\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "JtdhMZQQGAJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer and learning rate scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "metadata": {
        "id": "o2DLewUCGEYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation loops\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, targets in data_loader:\n",
        "        images = list(img.to(device) for img in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss_value\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch+1} Training -- Total Loss: {total_loss:.4f}, Average Loss: {avg_loss:.4f}\")\n",
        "    return total_loss, avg_loss\n"
      ],
      "metadata": {
        "id": "ZzPOkZnuGE_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate(model, data_loader, device, epoch):\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in data_loader:\n",
        "            images = list(img.to(device) for img in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            total_val_loss += losses.item()\n",
        "    avg_val_loss = total_val_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch+1} Validation -- Total Loss: {total_val_loss:.4f}, Average Loss: {avg_val_loss:.4f}\")\n",
        "    return total_val_loss, avg_val_loss"
      ],
      "metadata": {
        "id": "j18H2BRJGIOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run training\n",
        "epochs = 10\n",
        "training_stats = []\n",
        "for epoch in range(epochs):\n",
        "    train_total, train_avg = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
        "    val_total, val_avg = validate(model, val_loader, device, epoch)\n",
        "    lr_scheduler.step()\n",
        "    training_stats.append((train_total, train_avg, val_total, val_avg))"
      ],
      "metadata": {
        "id": "RCAqhmrSGLEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization on validation images\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def visualize_predictions(dataset, model, device, num_images=5):\n",
        "    model.eval()\n",
        "    for idx in range(min(num_images, len(dataset))):\n",
        "        img, target = dataset[idx]\n",
        "        orig = img.mul(255).permute(1, 2, 0).byte().numpy()\n",
        "\n",
        "        fig, ax = plt.subplots(1)\n",
        "        ax.imshow(orig)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model([img.to(device)])[0]\n",
        "        for box, label in zip(prediction['boxes'], prediction['labels']):\n",
        "            x1, y1, x2, y2 = box.tolist()\n",
        "            rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
        "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            ax.text(x1, y1, CLASS_MAP[int(label)], fontsize=10,\n",
        "                    color='white', backgroundcolor='red')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "visualize_predictions(val_dataset, model, device, num_images=5)\n"
      ],
      "metadata": {
        "id": "l3L5W5xPGNMv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}